# Что происходит с мономорфизмом?

В докладах и статьях о производительности JavaScript часто подчёркивают важность **мономорфного** кода. Однако они обычно не дают ясного объяснения того, что такое мономорфизм/полиморфизм и почему это важно. Даже в моих собственных докладах часто звучит что-то вроде «**ОДИН ТИП — ХОРОШО. ДВА ТИПА — ПЛОХО!!!**». Неудивительно, что одна из самых частых просьб ко мне — объяснить, *что такое мономорфизм на самом деле*, как возникает полиморфизм и почему это плохо.

Не помогает то, что само слово "полиморфизм" перегружено смыслами. В классическом объектно-ориентированном программировании *полиморфизм* обычно означает субтипизацию и возможность переопределить поведение базового класса. Программисты на Haskell подумают о параметрическом полиморфизме. Однако полиморфизм, против которого предостерегают доклады о производительности JS, — это нечто другое — это *полиморфизм в точке вызова*.

Я объяснял эту концепцию так много раз различными способами, что в конце концов решил написать эту статью — чтобы в следующий раз просто ссылаться на неё.

[Я также решил попробовать новый подход к объяснению вещей — пытаясь уловить взаимодействие между различными частями виртуальной машины с помощью коротких комиксов. Это новая область для меня, поэтому, пожалуйста, не стесняйтесь присылать мне обратную связь. Помогает ли это лучше понять? Или затрудняет понимание? Эта статья также пропускает различные детали, которые я считал неважными, избыточными или только косвенно связанными — смело присылайте вопросы, если вам кажется, что я что-то упустил]

## Динамический поиск 101

Для простоты эта статья будет в основном сосредоточена на самом простом поиске свойства в JavaScript, например `o.x` в коде ниже. В то же время важно понимать, что всё, о чём мы будем говорить, применимо к любой *динамически связанной* операции, будь то поиск свойства или арифметическая операция, и даже выходит за пределы JavaScript.

Представьте на мгновение, что вы проходите собеседование на отличную должность в Interpreters Ltd. и интервьюер просит вас спроектировать и реализовать поиск свойств для JS VM. Каким был бы самый простой и прямолинейный ответ?

Очевидно, что вы не можете сделать это проще, чем взять семантику JS такой, как она описана в ECMAScript Language Specification (aka ECMA 262), и переписать алгоритм [[Get]] слово в слово с английского на C++, Java, Rust или Malbolge — в зависимости от вашего языка программирования для собеседования.

На самом деле, если вы откроете любой JS интерпретатор, вы, скорее всего, обнаружите что-то в этом роде:

Это абсолютно верный способ реализации поиска свойств, однако у него есть одна серьёзная проблема: если мы сравним нашу реализацию поиска свойств с теми, что используются в современных JS VM, мы обнаружим, что это слишком медленно.

Наш интерпретатор *амнезичен*: каждый раз, когда он выполняет поиск свойства, он должен запустить общий алгоритм поиска свойства, он ничего не узнаёт из предыдущих попыток и должен платить полную цену снова и снова. Именно поэтому ориентированные на производительность VM реализуют поиск свойств иначе.

## Inline Caching

А что если бы каждый доступ к свойству в нашей программе был способен учиться на объектах, которые он видел раньше, и применять эти знания к похожим объектам? Потенциально это позволило бы нам сэкономить много времени, избежав дорогостоящего общего алгоритма поиска и вместо этого используя более быстрый, который применяется только к объектам определённой *формы*.

Мы знаем, что дорого выяснять, где находится данное свойство внутри произвольного объекта, поэтому нам бы хотелось выполнить этот поиск один раз, а затем поместить *путь* к этому свойству в кэш, используя *форму объекта* в качестве ключа. В следующий раз, когда мы увидим объект с той же формой, мы можем просто взять путь из кэша вместо того, чтобы вычислять его с нуля.

Эта техника оптимизации известна как **Inline Caching**, и я писал о ней раньше. Для этой статьи я оставлю детали конкретной реализации в стороне и вместо этого сосредоточусь на аспекте, который я раньше игнорировал: каждый inline cache прежде всего — это **кэш**, и как любой другой кэш он имеет *размер* (количество текущих записей в кэше) и *ёмкость* (максимальное количество записей в кэше).

Давайте ещё раз посмотрим на пример:

Каково ожидаемое количество кэшированных записей для IC на `o.x`?

Учитывая, что `{x: 1}` и `{x: 2}` имеют одну и ту же форму (также известную как *скрытый класс* или *map*), ответ — 1. Именно это состояние кэша мы называем *мономорфным*, потому что он видел объекты только одной формы. [моно- ("один") + -морфный ("имеющий форму")]

Что происходит, если мы теперь вызовем `f` с объектом другой формы?

`{x: 3}` и `{x: 3, y: 1}` — это объекты разных форм, поэтому кэш больше не является мономорфным, он теперь содержит две записи кэша: одну для формы `{x: *}` и одну для формы `{x: *, y: *}` — наша операция теперь находится в *полиморфном* состоянии со степенью полиморфизма `2`.

Если мы продолжим вызывать `f` с объектами разных форм, степень его полиморфизма будет продолжать расти до тех пор, пока не достигнет предопределённого порога — максимальной возможной ёмкости для inline cache (например, `4` для загрузок свойств в V8) — в этот момент кэш перейдёт в *мегаморфное* состояние.

Мегаморфное состояние существует для предотвращения неконтролируемого роста полиморфных кэшей, это означает *"я видел слишком много форм здесь, я сдаюсь и перестаю их отслеживать"*. В V8 мегаморфные IC по-прежнему могут продолжать кэшировать вещи, но вместо локального кэширования они помещают кэшируемые данные в глобальную хеш-таблицу. Эта хеш-таблица имеет фиксированный размер, и записи просто перезаписываются при коллизиях.

Теперь небольшое упражнение для проверки понимания:

- Сколько inline cache'ей для доступа к свойствам находится в функции `ff`?
- В каком состоянии они находятся?

Ответы: есть 2 кэша, оба мономорфны, потому что каждый видит объекты только одной формы.

## Последствия для производительности

На этом этапе характеристики производительности различных состояний IC должны стать понятны:

- мономорфный — это самое быстрое возможное состояние IC, если вы всегда попадаете в кэш (**ОДИН ТИП — ХОРОШО**);
- IC в полиморфном состоянии выполняют линейный поиск среди кэшированных записей;
- IC в мегаморфном состоянии проверяют глобальную хеш-таблицу и, таким образом, самые медленные среди всех IC, но попадание в глобальный кэш всё ещё лучше, чем полный промах IC;
- промах IC дорог — вы должны платить за переход в runtime плюс стоимость общей операции.

Однако это только половина правды: в дополнение к ускорению вашего кода inline cache'и также служат *шпионами* для всемогущего оптимизирующего компилятора — который в конце концов придёт и попытается ускорить ваш код ещё больше.

## Спекуляции и оптимизации

Inline cache'и не могут обеспечить пиковую производительность сами по себе из-за двух проблем:

- каждый IC действует самостоятельно, ничего не зная о своих соседях;
- каждый IC в конечном итоге может вернуться в runtime, если он не может обработать свой ввод: что означает, что это по сути общая операция с общими побочными эффектами и часто неизвестным типом результата.

Например, в функции выше каждый IC (их 7: `.x`, `.x`, `*`, `.y`, `.y`, `*`, `+`) действует самостоятельно. Каждый IC загрузки свойства будет проверять `o` против одного и того же кэшированного формы. Арифметический IC на `+` будет проверять, являются ли его входы числами (и какие виды чисел — так как V8 внутренне имеет различные представления чисел) — хотя это можно было бы вывести из состояния `*` IC.

Арифметические операции в JavaScript по сути типированы, например `a|0` всегда возвращает 32-битное целое число и `+a` всегда возвращает число, но большинство других операций не имеют таких гарантий. Это превращает написание ahead-of-time оптимизирующего компилятора для JavaScript в экстремально сложную проблему. Вместо компиляции JavaScript один раз в AOT стиле, большинство JavaScript VM имеют несколько уровней исполнения. Например, в V8 код начинает выполняться без каких-либо оптимизаций, скомпилированный нетранслирующим базовым компилятором. Горячие функции позже перекомпилируются оптимизирующим компилятором.

[asm.js использует эту неотъемлемую типизацию для определения экстремально ограниченного подмножества JavaScript, которое полностью статически типизировано и может быть оптимизировано ahead-of-time, устраняя необходимость в спекулятивной адаптивной компиляции]

Ожидание, пока код прогреется, служит двум различным целям:

- это снижает задержку запуска: оптимизирующий компилятор медленнее, чем нетранслирующий, что означает, что оптимизированный код должен использоваться достаточно часто, чтобы оптимизации окупились;
- это даёт inline cache'ам шанс собрать *обратную связь по типам*.

Как уже подчёркивалось выше, JavaScript, написанный человеком, обычно не содержит достаточно информации о встроенных типах, чтобы позволить полную статическую типизацию и AOT компиляцию. JIT должен спекулировать: он должен делать *обоснованные* предположения об использовании и поведении кода, который он оптимизирует, и генерировать специализированный код, который действителен при определённых предположениях. Другими словами, компилятор должен угадать, какие виды объектов видны в конкретном месте функции, которую он оптимизирует. По счастливому совпадению, это именно информация, которую собирают inline cache'и!

- Мономорфный кэш говорит "я видел **только** тип A";
- Полиморфный кэш степени N говорит "я видел **только** A₁, …, Aₙ";
- Мегаморфный кэш говорит "я видел много разных вещей".

Оптимизирующий компилятор смотрит на информацию, собранную inline cache'ами, и строит *промежуточное представление* (IR) соответственно. Инструкции IR обычно более специфичны и низкоуровневы, чем общие JS операции. Например, если IC для `.x` видел только объекты формы `{x, y}`, то оптимизатор может использовать инструкцию IR, которая загружает свойство с фиксированного смещения внутри объекта для загрузки `.x`. Конечно, небезопасно применять такую инструкцию к произвольным объектам, поэтому оптимизатор добавляет *проверку типа* перед ней. Проверка типа проверяет форму объекта перед тем, как он достигнет специализированной операции, и если он не совпадает с ожидаемой формой, выполнение оптимизированного кода **не может** продолжиться — вместо этого нам нужно прыгнуть в неоптимизированный код и продолжить выполнение там. Этот процесс называется *деоптимизацией*. Причины деоптимизации, однако, не ограничиваются нарушением проверки типа: арифметическая операция может быть специализирована для 32-битных целых чисел и деоптимизируется, если результат переполнит это представление, доступ к индексированному свойству `arr[idx]` может быть специализирован для доступа в пределах границ и деоптимизируется, если `idx` выходит за границы или `arr` не имеет свойства `idx` (это *hole*), и т.д.

Теперь должно быть ясно, что процесс оптимизации пытается решить две ранее описанные слабости:

| неоптимизированный | оптимизированный |
|---|---|
| каждая операция имеет произвольные неизвестные побочные эффекты, потому что она общая и реализует полную семантику | специализации кода ограничивают или устраняют непредсказуемость, побочные эффекты хорошо определены (например, загрузка свойства по смещению не имеет побочных эффектов) |
| каждая операция независима, учится индивидуально и не обменивается информацией с соседями | операции разлагаются на низкоуровневые инструкции IR, которые затем оптимизируются вместе, это позволяет обнаружить и устранить избыточность между ними |

Действительно, построение специализированного IR на основе обратной связи по типам — это только первый шаг в конвейере оптимизации. Как только IR готов, компилятор запустит несколько проходов по нему, пытаясь обнаружить инварианты и устранить избыточность. Анализы, которые запускаются на этом этапе, обычно *внутрипроцедурные*, и компилятор вынужден предполагать худшие произвольные побочные эффекты каждый раз, когда он встречает вызов. Здесь важно понимать, что общие неспециализированные операции по сути являются *вызовами* сами по себе: например, оценка `+` может вызвать `valueOf`, а доступ к свойству `o.x` может легко привести к вызову getter'а. Это означает, что любая операция, которую оптимизатор по какой-то причине не смог полностью специализировать, может стать камнем преткновения для последующих проходов оптимизации.

Один очень частый случай избыточности — повторяющиеся проверки типа, которые проверяют одно и то же значение против одной и той же формы. Вот как мог бы выглядеть начальный IR для функции `g` (см. выше):

```
CheckMap v0, {x,y}   ;; проверка формы
v1 Load v0, @12      ;; загрузка o.x
CheckMap v0, {x,y}
v2 Load v0, @12      ;; загрузка o.x
i3 Mul v1, v2        ;; o.x * o.x
CheckMap v0, {x,y}
v4 Load v0, @16      ;; загрузка o.y
CheckMap v0, {x,y}
v5 Load v0, @16      ;; загрузка o.y
i6 Mul v4, v5        ;; o.y * o.y
i7 Add i3, i6        ;; o.x * o.x + o.y * o.y
```

Этот IR проверяет `v0` против одной и той же формы 4 раза, хотя между проверками нет ничего, что могло бы повлиять на форму `v0`. Внимательный читатель также заметит, что загрузки `v2` и `v5` также избыточны, так как ничто не переписывает соответствующие свойства. К счастью, проход GVN, который позже применяется к IR, устранит избыточные проверки и загрузки:

```
;; После GVN
CheckMap v0, {x,y}
v1 Load v0, @12
i3 Mul v1, v1
v4 Load v0, @16
i6 Mul v4, v4
i7 Add i3, i6
```

Однако, как отмечалось выше, такое устранение возможно только потому, что между избыточными операциями нет мешающих побочных эффектов: если бы был вызов между `v1` и `v2`, нам пришлось бы консервативно предположить, что вызванная функция потенциально может иметь доступ к `v0` и, таким образом, может добавлять, удалять и изменять свойства — это сделало бы невозможным устранение доступа `v2` или `CheckMap`, который его охраняет.

Теперь, когда мы понимаем оптимизирующий компилятор и знаем, что ему нравится (специализированные операции) и что ему не нравится (вызовы и общие операции), остаётся только одно обсудить: обработка неполиморфных операций оптимизирующим компилятором.

## Полиморфные операции

Если операция неполиморфна, оптимизирующий компилятор, очевидно, не может использовать это простое правило специализации `проверка-типа + специализированная-операция`, которое мы обсуждали выше. Он просто не сможет выбрать единственный тип для проверки типа и единственную специализированную операцию. IC говорит компилятору, что эта операция видит значения различных типов/форм, поэтому выбор одного из них и игнорирование остальных означает рискнуть деоптимизацией, что крайне нежелательно. Вместо этого оптимизирующий компилятор обычно попытается построить *дерево решений*. Например, полиморфный доступ к свойству `o.x`, который видел формы `A`, `B`, `C`, будет развёрнут в что-то вроде этого (отметим, что это псевдокод — оптимизирующий компилятор построит структуру CFG вместо этого):

Одна вещь, на которую стоит обратить внимание, это то, что полиморфные доступы не имеют полезного свойства, которое имеют мономорфные доступы. После специализированного мономорфного доступа и до мешающего побочного эффекта мы можем гарантировать, что объект имеет определённую форму. Это позволяет устранить избыточность между мономорфными доступами. Полиморфные доступы дают очень слабую гарантию "форма объекта — одна из A, B, C". Мы не можем использовать эту информацию для устранения большой избыточности между двумя похожими полиморфными доступами, которые следуют друг за другом (максимум мы могли бы использовать её для устранения последней сравнения и блока деоптимизации — но V8 не делает этого).

## Оптимизированный полиморфный доступ

V8, однако, строит более эффективный IR, если свойство находится в одном и том же месте во *всех* формах. В этом случае вместо дерева решений будет выпущена проверка полиморфного типа:

Этот IR имеет одно важное преимущество для устранения избыточности: если между двумя инструкциями `$TypeGuard(o, [A, B, C])` нет мешающих побочных эффектов, то вторая из них избыточна, как в мономорфном случае.

Если обратная связь по типам говорит оптимизирующему компилятору, что доступ к свойству видел больше различных форм, чем компилятор считает целесообразным обработать встроенным образом, то оптимизатор вместо этого построит немного другое дерево решений, которое заканчивается общей операцией вместо деоптимизации:

Наконец, в некоторых случаях оптимизирующий компилятор может полностью отказаться от специализации операций:

- если он не знает, как её эффективно специализировать;
- операция полиморфна и оптимизатор не знает, как правильно построить для неё дерево решений (например, раньше это было так для полиморфных доступов с ключом `arr[i]` в V8 — но уже не так);
- операция не имеет никакой действенной обратной связи по типам для специализации (операция никогда не выполнялась, GC очистил собранную обратную связь по типам, и т.д.)

Во всех таких (довольно редких) случаях оптимизатор просто выпускает общий вариант операции в IR.

## Следствия для производительности

Давайте суммируем то, что мы узнали:

- мономорфные операции легче всего специализировать, дают оптимизатору наиболее полезную информацию и позволяют дальнейшие оптимизации. По словам Халка: **ОДИН ТИП БЛИЗКО К МЕТАЛЛУ**!

- умеренно полиморфные операции, которые требуют проверку полиморфного типа или, в худшем случае, дерево решений, медленнее мономорфных.

- Деревья решений усложняют поток управления и затрудняют для оптимизатора распространение типов и устранение избыточности. Условные переходы, зависящие от памяти, которые составляют эти деревья решений, могут быть плохой новостью, если полиморфная операция находится прямо в середине плотного цикла вычислений;

- проверки полиморфного типа не препятствуют потоку типов столь сильно и всё ещё позволяют некоторое устранение избыточности — но каждая проверка полиморфного типа всё ещё несколько медленнее, чем мономорфная проверка типа (которая проверяет одну форму). Штраф производительности за проверку полиморфного типа зависит от того, насколько хорошо процессор обрабатывает условные ветвления;

- высоко полиморфные/мегаморфные операции вообще не специализируются и приводят к выпуску общей операции как части оптимизированного IR. Эта общая операция — вызов — со всеми связанными с этим отрицательными последствиями как для оптимизаций, так и для прямой производительности процессора.

Посмотрите на этот микробенчмарк, пытающийся уловить разницу между всеми этими случаями для доступа к свойству: мономорфный, полиморфный с совпадающими смещениями свойств (требует проверку полиморфного типа), полиморфный с разными смещениями свойств (требует дерево решений), мегаморфный.

## Не обсуждалось

Я намеренно игнорировал некоторые детали реализации при написании этой статьи, чтобы избежать излишне расширенного объёма.

### Формы

Мы вообще не обсуждали, как формы (также известные как скрытые классы) представлены, вычисляются и прикрепляются к объектам. Посмотрите мою статью об inline cache'ах, некоторые мои доклады, например, AWP2014, чтобы получить базовое понимание.

Одна важная вещь, которую нужно понимать, это что понятие *формы* в JavaScript VM — это эвристическое приближение. Это попытка динамически аппроксимировать статическую структуру, скрытую в программе. Вещи, которые имеют одну форму для человека, могут не обязательно иметь одну форму для VM:

Словарная природа объектов JavaScript также облегчает создание *случайного* полиморфизма:

### Преднамеренный полиморфизм

Даже если вы программируете на языке, который позволяет вам только инстанцировать объекты фиксированной формы (Java, C#, Dart, C++, и т.д.) из жёстких классов, вы всё ещё можете писать полиморфный код:

Возможность писать код против *интерфейса* и иметь этот код процесса объектов различных *реализаций* — это важный механизм абстракции. Полиморфизм в статически типизированных языках программирования имеет сходные последствия для производительности с теми, что обсуждались выше.

[неудивительно, что JVM'ы используют inline cache'и для оптимизации вызовов `invokeinterface` и `invokevirtual`]

### Не все кэши одинаковы

Может быть хорошей идеей помнить, что некоторые кэши не основаны на формах и/или имеют более низкую *ёмкость*, чем другие. Например, кэш, связанный с вызовом функции, является либо неинициализированным, мономорфным, либо мегаморфным без промежуточного полиморфного состояния. Вместо кэширования формы функции, которая не имеет отношения к вызову, она кэширует *целевой вызов* — то есть саму функцию.

Если `inv` оптимизирована, когда inline cache для вызова `cb(...)` мономорфен, то оптимизирующий компилятор потенциально может встроить этот вызов (что очень важно для маленьких функций на горячих путях). Когда этот кэш мегаморфен, оптимизатор не сможет встроить что-либо (он не знает *что* — так как нет единственной цели) и просто оставит общую операцию вызова в IR.

Это контрастирует с выражениями вызова метода `o.m(...)`, которые обрабатываются аналогично доступам к свойствам. IC'и в точках вызова метода имеют промежуточное полиморфное состояние между мономорфным и мегаморфным состояниями. V8 способен встраивать в мономорфные, полиморфные и мегаморфные точки, и он строит IR таким же образом, как для свойств: выбирая между деревом решений или единственной проверкой полиморфного типа перед телом встроенной функции. Однако есть одно ограничение: чтобы V8 мог встроить вызов метода, ему нужно, чтобы *это было частью формы*.

[в действительности `o.m(...)` компилируется в два IC'и: один `LoadIC`, который выполняет загрузку свойства, и другой `CallIC`, который вызывает загруженное свойство с надлежащим получателем и аргументами. `CallIC` — это тот же вид IC, который описан выше для вызовов вроде `cb(...)`. Он способен записывать только мономорфное или мегаморфное состояние. Вот почему его состояние игнорируется при оптимизации вызова метода и используется только состояние IC'а загрузки свойства]

Может быть удивительно, что `f` и `g` имеют разные формы выше. Это происходит потому, что когда мы присваиваем функцию свойству, V8 пытается (если возможно) прикрепить её к форме объекта вместо того, чтобы сохранять её непосредственно на объекте. В этом примере `f` имеет форму вроде `{cb: F}`, то есть сама форма указывает напрямую на замыкание. В наших предыдущих примерах у нас были только формы, которые просто объявляли наличие свойства на определённом смещении, однако эта форма также захватывает значение свойства. Это делает формы V8 похожими на классы в языке вроде Java или C++, где класс по сути является набором *полей* **и методов**.

Конечно, если вы позже перепишете функциональное свойство другой функцией, V8 решает, что это не выглядит как отношение класс-метод, и переключается на форму, которая отражает это:

В целом, тема того, как V8 строит и поддерживает формы (скрытые классы), достойна отдельной большой статьи сама по себе.

### Представление *пути-к-свойству*

На этом этапе может показаться, что IC, связанный со свойством `o.x`, — это просто словарь, отображающий формы на смещения свойств, что-то вроде `Dictionary<Shape, int>`. Однако это представление слишком узко, чтобы быть полезным: свойство может находиться на одном из объектов в цепи прототипов или быть *свойством аксессора* (таким, которое имеет getter и/или setter). Интересное наблюдение, которое нужно сделать здесь, это что свойства аксессора в определённом смысле более общие, чем нормальные свойства данных.

Например, `o = {x: 1}` может быть воспринято как объект со свойством аксессора `x`, которое имеет getter/setter, обращающиеся к скрытому внутреннему слоту, используя встроенные функции VM'а:

[Dart VM реализует доступ к полям таким образом]

В свете этого наблюдения становится ясно, что IC должен быть более похож на `Dictionary<Shape, Function>`: отображение форм на функции аксессора, которые должны быть выполнены, если IC попадает. Такое представление IC позволило бы оптимизировать случаи, которые были невозможно покрыть с помощью упрощённого представления из выше (свойства в цепи прототипов, свойства аксессора и даже объекты ES6 proxy).

[в действительности IC'и V8 — это пропатченные точки вызова, которые вызывают специально созданные для IC runtime stub'ы, см. эту статью для более точной аналогии]

### Состояние до мономорфизма

Некоторые IC'и в V8 фактически имеют так называемое *состояние до мономорфизма* между *неинициализированным* и *мономорфным*. Оно существует, чтобы избежать компилирования IC stub'ов для IC'ей, которые выполняются только один раз. Я решил избежать обсуждения этого состояния, потому что это довольно неясная деталь реализации.

## Финальный совет по производительности

Лучший совет по производительности скрыт в названии книги Дейла Карнеги "Как перестать беспокоиться и начать жить".

Действительно, беспокойство о полиморфизме обычно бесполезно. Вместо этого профилируйте ваш код на реалистичном наборе данных, ищите горячие точки и если какие-либо из них связаны с JS — посмотрите IR, который производит оптимизирующий компилятор.

Если в середине вашего плотного цикла вычислений числа вы видите инструкцию IR, называемую `XYZGeneric`, или что-либо отмеченное красной меткой `changes[*]` (т.е. "изменяет всё") — тогда (только тогда!) это может быть правильное время, чтобы начать беспокоиться.

---

